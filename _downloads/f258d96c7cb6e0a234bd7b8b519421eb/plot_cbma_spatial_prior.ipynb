{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Example where a spatial prior is defined based on the distance between voxels and foci in a coordinate-based meta-analysis database\n\nEach voxel's probability of being reported by a study is calculated based on\nwhether that particular study reports a focus (peak activation) near the voxel.\nThe probability is defined based on how far from the focus that voxel happens\nto be.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import warnings\n\nwarnings.filterwarnings(\"ignore\")\n\nfrom pathlib import Path\nfrom typing import Iterable\n\nimport nibabel\nimport nilearn.datasets\nimport nilearn.image\nimport nilearn.plotting\nimport numpy as np\nfrom neurolang.frontend import ExplicitVBR, ExplicitVBROverlay, NeurolangPDL\nfrom neurolang.frontend.neurosynth_utils import get_ns_mni_peaks_reported\n\n# ##############################################################################\n# Data preparation\n# ----------------\n\ndata_dir = Path.home() / \"neurolang_data\"\n\n# ##############################################################################\n# Load the MNI atlas and resample it to 4mm voxels\n\nmni_t1 = nibabel.load(\n    nilearn.datasets.fetch_icbm152_2009(data_dir=str(data_dir / \"icbm\"))[\"t1\"]\n)\nmni_t1_2mm = nilearn.image.resample_img(mni_t1, np.eye(3) * 2)\n\n# ##############################################################################\n# Probabilistic Logic Programming in NeuroLang\n# --------------------------------------------\n\nnl = NeurolangPDL()\n\n\n# ##############################################################################\n# Adding new aggregation function to build a region overlay\n# ----------------------------------\n\n\n@nl.add_symbol\ndef agg_create_region_overlay(\n    i: Iterable, j: Iterable, k: Iterable, p: Iterable\n) -> ExplicitVBR:\n    voxels = np.c_[i, j, k]\n    return ExplicitVBROverlay(\n        voxels, mni_t1_2mm.affine, p, image_dim=mni_t1_2mm.shape\n    )\n\n\n# ##############################################################################\n# Loading the database\n# ----------------------------------\n\npeak_data = get_ns_mni_peaks_reported(data_dir)\nijk_positions = np.round(\n    nibabel.affines.apply_affine(\n        np.linalg.inv(mni_t1_2mm.affine),\n        peak_data[[\"x\", \"y\", \"z\"]].values.astype(float),\n    )\n).astype(int)\npeak_data[\"i\"] = ijk_positions[:, 0]\npeak_data[\"j\"] = ijk_positions[:, 1]\npeak_data[\"k\"] = ijk_positions[:, 2]\npeak_data = peak_data[[\"i\", \"j\", \"k\", \"id\"]]\n\nnl.add_tuple_set(peak_data, name=\"FocusReported\")\nstudy_ids = nl.load_neurosynth_study_ids(data_dir, \"Study\")\nnl.add_uniform_probabilistic_choice_over_set(\n    study_ids.value, name=\"SelectedStudy\"\n)\nnl.load_neurosynth_term_study_associations(\n    data_dir, \"TermInStudyTFIDF\", tfidf_threshold=1e-3\n)\nVoxel = nl.add_tuple_set(\n    np.hstack(\n        np.meshgrid(\n            *(np.arange(0, dim) for dim in mni_t1_2mm.get_fdata().shape)\n        )\n    )\n    .swapaxes(0, 1)\n    .reshape(3, -1)\n    .T,\n    name=\"Voxel\",\n)\n\n# ##############################################################################\n# Probabilistic program and querying\n# ----------------------------------\n\n\nwith nl.environment as e:\n    (e.VoxelReported @ e.max(e.exp(-e.d / 5.0)))[e.i1, e.j1, e.k1, e.s] = (\n        e.FocusReported(e.i2, e.j2, e.k2, e.s)\n        & e.Voxel(e.i1, e.j1, e.k1)\n        & (e.d == e.EUCLIDEAN(e.i1, e.j1, e.k1, e.i2, e.j2, e.k2))\n        & (e.d < 1)\n    )\n    e.TermAssociation[e.t] = (\n        e.SelectedStudy[e.s] & e.TermInStudyTFIDF[e.s, e.t, ...]\n    )\n    e.Activation[e.i, e.j, e.k] = (\n        e.SelectedStudy[e.s] & e.VoxelReported[e.i, e.j, e.k, e.s]\n    )\n    e.probmap[e.i, e.j, e.k, e.PROB[e.i, e.j, e.k]] = (\n        e.Activation[e.i, e.j, e.k]\n    ) // e.TermAssociation[\"emotion\"]\n    e.img[e.agg_create_region_overlay[e.i, e.j, e.k, e.p]] = e.probmap[\n        e.i, e.j, e.k, e.p\n    ]\n    img_query = nl.query((e.x,), e.img[e.x])\n\n# ##############################################################################\n# Plotting results\n# --------------------------------------------\n\nresult_image = img_query.fetch_one()[0].spatial_image()\nimg = result_image.get_fdata()\nplot = nilearn.plotting.plot_stat_map(\n    result_image, threshold=np.percentile(img[img > 0], 95)\n)\nnilearn.plotting.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}